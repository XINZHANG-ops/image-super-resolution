{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "electronic-spiritual",
   "metadata": {},
   "source": [
    "# Note\n",
    "### probably need to modify hdf5_format.py in /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/, remove all .decode('utf-8') part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../YOLOv5-Classifier/linmao_classification/JPEGImages/8/nl_0098_0386.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open(img_path)\n",
    "lr_img = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread(img_path)\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "img_size = 128\n",
    "\n",
    "resized_arr = cv2.resize(img, (img_size, img_size)) # Reshaping images to preferred size\n",
    "imgplot = plt.imshow(resized_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISR.models import RDN, RRDN, Cut_VGG19\n",
    "\n",
    "name = ['psnr-small', 'psnr-large', 'noise-cancel', 'RRDN-gans']\n",
    "rdn_small = RDN(weights='psnr-small') #psnr-large #psnr-small #noise-cancel\n",
    "rdn_large = RDN(weights='psnr-large') #psnr-large #psnr-small #noise-cancel\n",
    "rdn_noise = RDN(weights='noise-cancel') #psnr-large #psnr-small #noise-cancel\n",
    "rrdn = RRDN(weights='gans', beta=0.2) # beta=0.2 is just good\n",
    "\n",
    "models = [rdn_small, rdn_large, rdn_noise, rrdn]\n",
    "results = []\n",
    "for m in models:\n",
    "    sr_img = m.predict(lr_img)\n",
    "    results.append(sr_img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1,5,1)\n",
    "resized_arr = cv2.resize(img, (img_size, img_size)) # Reshaping images to preferred size\n",
    "imgplot = plt.imshow(resized_arr)\n",
    "plt.title(f'origin {img.shape}')\n",
    "\n",
    "for idx, m_type in enumerate(name):\n",
    "    plt.subplot(1,5,idx+2)\n",
    "    sr_img = results[idx]\n",
    "    resized_arr = cv2.resize(sr_img, (img_size, img_size)) # Reshaping images to preferred size\n",
    "    imgplot = plt.imshow(resized_arr)\n",
    "    plt.title(f'{m_type} {sr_img.shape}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-parallel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-consultation",
   "metadata": {},
   "source": [
    "# Super resolution for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "considerable-reality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method MultiplyBeta.call of <ISR.models.rrdn.MultiplyBeta object at 0x7fd8c44c6710>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method MultiplyBeta.call of <ISR.models.rrdn.MultiplyBeta object at 0x7fd8c44c6710>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method PixelShuffle.call of <ISR.models.rrdn.PixelShuffle object at 0x7fd8be284910>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method PixelShuffle.call of <ISR.models.rrdn.PixelShuffle object at 0x7fd8be284910>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "from ISR.models import RDN, RRDN, Cut_VGG19\n",
    "\n",
    "rrdn = RRDN(weights='gans', beta=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "primary-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "provincial-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_img_dir = '../YOLOv5-Classifier/linmao_classification/JPEGImages'\n",
    "out_put_dir = 'linmao_classification_super'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "revolutionary-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "finished_names = set()\n",
    "for root, dirs, files in os.walk(out_put_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".JPG\"):\n",
    "            if 'checkpoint' in file:\n",
    "                pass\n",
    "            else:\n",
    "                the_path = os.path.join(root, file)\n",
    "                img_name = os.path.splitext(the_path.split(os.sep)[-1])[0]\n",
    "                finished_names.add(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7805 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd8c425d680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd8c425d680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "image_path = []\n",
    "for root, dirs, files in os.walk(cls_img_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".JPG\"):\n",
    "            if 'checkpoint' in file:\n",
    "                pass\n",
    "            else:\n",
    "                the_path = os.path.join(root, file)\n",
    "                img_name = os.path.splitext(the_path.split(os.sep)[-1])[0]\n",
    "                if img_name in finished_names:\n",
    "                    pass\n",
    "                else:\n",
    "                    image_path.append(the_path)\n",
    "\n",
    "\n",
    "    \n",
    "for img_p in tqdm(image_path):\n",
    "    sub_path = img_p.replace(cls_img_dir+'/', '')\n",
    "    if len(sub_path.split('/')) > 1:\n",
    "        sub_dir = sub_path.split('/')[0]\n",
    "        save_dir = os.path.join(out_put_dir, sub_dir)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    else:\n",
    "        save_dir = out_dir\n",
    "    img_name = os.path.splitext(img_p.split(os.sep)[-1])[0]\n",
    "    img = Image.open(img_p)\n",
    "    lr_img = np.array(img)\n",
    "    sr_img = rrdn.predict(lr_img)\n",
    "    save_path = os.path.join(save_dir, img_name+'.jpg')\n",
    "    cv2.imwrite(save_path, sr_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-beverage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-conjunction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-henry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-fishing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-preservation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-change",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-character",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-adventure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-cheat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISR.models import RRDN\n",
    "from ISR.models import Discriminator\n",
    "from ISR.models import Cut_VGG19\n",
    "\n",
    "lr_train_patch_size = 40\n",
    "layers_to_extract = [5, 9]\n",
    "scale = 2\n",
    "hr_train_patch_size = lr_train_patch_size * scale\n",
    "\n",
    "rrdn  = RRDN(arch_params={'C':4, 'D':3, 'G':64, 'G0':64, 'T':10, 'x':scale}, patch_size=lr_train_patch_size)\n",
    "f_ext = Cut_VGG19(patch_size=hr_train_patch_size, layers_to_extract=layers_to_extract)\n",
    "discr = Discriminator(patch_size=hr_train_patch_size, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-diabetes",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISR.train import Trainer\n",
    "loss_weights = {\n",
    "  'generator': 0.0,\n",
    "  'feature_extractor': 0.0833,\n",
    "  'discriminator': 0.01\n",
    "}\n",
    "losses = {\n",
    "  'generator': 'mae',\n",
    "  'feature_extractor': 'mse',\n",
    "  'discriminator': 'binary_crossentropy'\n",
    "}\n",
    "\n",
    "log_dirs = {'logs': './logs', 'weights': './weights'}\n",
    "\n",
    "learning_rate = {'initial_value': 0.0004, 'decay_factor': 0.5, 'decay_frequency': 30}\n",
    "\n",
    "flatness = {'min': 0.0, 'max': 0.15, 'increase': 0.01, 'increase_frequency': 5}\n",
    "\n",
    "trainer = Trainer(\n",
    "    generator=rrdn,\n",
    "    discriminator=discr,\n",
    "    feature_extractor=f_ext,\n",
    "    lr_train_dir='low_res/training/images',\n",
    "    hr_train_dir='high_res/training/images',\n",
    "    lr_valid_dir='low_res/validation/images',\n",
    "    hr_valid_dir='high_res/validation/images',\n",
    "    loss_weights=loss_weights,\n",
    "    learning_rate=learning_rate,\n",
    "    flatness=flatness,\n",
    "    dataname='image_dataset',\n",
    "    log_dirs=log_dirs,\n",
    "    weights_generator=None,\n",
    "    weights_discriminator=None,\n",
    "    n_validation=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(\n",
    "    epochs=80,\n",
    "    steps_per_epoch=500,\n",
    "    batch_size=16,\n",
    "    monitored_metrics={'val_PSNR_Y': 'max'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-webcam",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-animation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-cleveland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "rapids-gpu.0-18.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/rapids-gpu.0-18:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
